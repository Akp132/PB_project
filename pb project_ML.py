# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R1n25CmP4Qe4Zln7kGz5EgTGEnjNIdjV
"""




####loading the datasets##########
pip install wandb

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Load the datasets
train_data = pd.read_csv("/content/drive/MyDrive/colab_files/trainData.csv")
train_labels = pd.read_csv("/content/drive/MyDrive/colab_files/trainLabels.csv")
test_data = pd.read_csv("/content/drive/MyDrive/colab_files/valData.csv")
test_labels = pd.read_csv("/content/drive/MyDrive/colab_files/valLabels.csv")

print("Train data shape:", train_data.shape)
print("Train labels shape:", train_labels.shape)
print("Test data shape:", test_data.shape)
print("Test labels shape:", test_labels.shape)





#############   running neural network   ###############

import wandb
from wandb.keras import WandbCallback

# Encode the labels
label_encoder = LabelEncoder()
train_labels_encoded = label_encoder.fit_transform(train_labels)
test_labels_encoded = label_encoder.transform(test_labels)

# Scale the data
scaler = StandardScaler()
train_data_scaled = scaler.fit_transform(train_data)
test_data_scaled = scaler.transform(test_data)

# Create a neural network model
model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(train_data_scaled.shape[1],)))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Initialize W&B and set up a new run
wandb.init(project='PB', entity='pbproject', name='run3')

# Train the model with WandbCallback
history = model.fit(train_data_scaled, train_labels_encoded, epochs=100, batch_size=32,
                    callbacks=[WandbCallback()])

# Evaluate the model on the test data
test_loss, test_accuracy = model.evaluate(test_data_scaled, test_labels_encoded)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)






############   SVM   ##############





#Create a Support Vector Machine (SVM) classifier
svm = SVC(kernel='linear')

gnb = GaussianNB()
dt = DecisionTreeClassifier()


# Train the SVM classifier on the training data
#svm.fit(train_data, train_labels.values.ravel())

gnb.fit(train_data, train_labels_encoded)

dt.fit(train_data, train_labels_encoded)

# Make predictions on the validation data
#val_predictions = svm.predict(val_data)

val_predictions_gnb = gnb.predict(val_data)
val_predictions_dt = dt.predict(val_data)

# Combine predictions
val_combined_predictions = np.array([val_predictions_gnb.astype(int), val_predictions_dt.astype(int)])
val_majority_vote = np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis=0, arr=val_combined_predictions)

# Calculate the accuracy of the combined classifiers
accuracy_combined = accuracy_score(val_labels_encoded, val_majority_vote)
print("Validation Accuracy (Combined): ", accuracy_combined)

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Create a Support Vector Machine (SVM) classifier
svm = SVC(kernel='linear')

# Train the SVM classifier on the training data
svm.fit(train_data, train_labels.values.ravel())

# Make predictions on the validation data
val_predictions = svm.predict(val_data)

# Calculate the accuracy of the SVM classifier
accuracy = accuracy_score(val_labels, val_predictions)
print("Validation Accuracy: ", accuracy)



#############  Random Forrest    ########################

 from sklearn.ensemble import RandomForestClassifier
 from sklearn.metrics import accuracy_score

 # Initialize the Random Forest classifier
 rf = RandomForestClassifier(n_estimators=100, random_state=42)

 # Train the classifier using the training data
 rf.fit(train_data, train_labels.values.ravel())

 # Make predictions on the validation data
 val_predictions_rf = rf.predict(val_data)

 # Calculate the accuracy of the classifier on the validation data
 val_accuracy_rf = accuracy_score(val_labels, val_predictions_rf)
 print("Validation Accuracy (Random Forest):", val_accuracy_rf)

 # Make predictions on the test data
 test_predictions_rf = rf.predict(test_data)

 # Calculate the accuracy of the classifier on the test data
 test_accuracy_rf = accuracy_score(test_labels, test_predictions_rf)
 print("Test Accuracy (Random Forest):", test_accuracy_rf)


